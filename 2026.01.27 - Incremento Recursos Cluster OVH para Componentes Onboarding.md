# Incremento de Recursos del Cluster OVH para Componentes de Onboarding

**Fecha:** 27 de Enero de 2026  
**Objetivo:** Ampliar la capacidad del cluster Kubernetes en OVH para poder desplegar los componentes necesarios para el proceso de onboarding (BPDM, SSI Credential Issuer, etc.)

---

## 1. Problema a Solucionar

### 1.1. Descripci√≥n del Problema

El cluster de Kubernetes en OVH (GRA5) tiene recursos insuficientes para desplegar todos los componentes necesarios para realizar el onboarding de empresas (Ikerlan, Orona, Fagor) en Catena-X.

**S√≠ntomas observados:**
- Intento fallido de desplegar componentes de onboarding (26/01/2026)
- M√∫ltiples pods en estado `CrashLoopBackOff`
- Pods en estado `Pending` por falta de recursos
- Pods con `ImagePullBackOff` debido a falta de recursos para provisionamiento de PersistentVolumes
- CPU al 80-83% de uso en 2 de 3 nodos

**Componentes que fallaron al desplegar:**
```
portal-bpdm-gate                     0/1   CrashLoopBackOff
portal-bpdm-pool                     0/1   CrashLoopBackOff
portal-bpdm-cleaning-service-dummy   0/1   Error/CrashLoopBackOff
portal-issuer-postgresql-0           0/1   Pending
smtp4dev                             0/1   Pending
portal-ssi-credential-issuer         0/1   CrashLoopBackOff
```

### 1.2. C√≥mo se Identific√≥ el Problema

#### Comandos de Diagn√≥stico Utilizados:

**1. Estado de pods problem√°ticos:**
```bash
export KUBECONFIG=/home/xmendialdua/projects/assembly/tractus-x-umbrella/kubeconfig.yaml
kubectl get pods --all-namespaces --field-selector=status.phase!=Running,status.phase!=Succeeded
```

**2. An√°lisis de recursos del cluster:**
```bash
# Listar nodos del cluster
kubectl get nodes

# Ver uso actual de CPU y memoria
kubectl top nodes

# Ver recursos asignados vs disponibles
kubectl describe nodes | grep -A 5 "Allocated resources"

# Ver capacidad total de CPU y memoria
kubectl describe nodes | grep -E "Name:|cpu:|memory:" | head -20
```

**3. Verificar PersistentVolumes:**
```bash
kubectl get pv
kubectl get pvc --all-namespaces
```

**4. Contar pods activos:**
```bash
kubectl get pods --all-namespaces | wc -l
```

### 1.3. Resultados del Diagn√≥stico

**Cluster actual (26/01/2026):**

```
Configuraci√≥n:
- Proveedor: OVH Public Cloud (regi√≥n GRA5)
- Cluster: dataspace (Kubernetes 1.34)
- Nodepool: tractus-x-umbrella
- Flavor: b2-7 (General Purpose)
- N√∫mero de nodos: 3

Especificaciones por nodo (b2-7):
- CPU: 2 vCores (1.84 vCores allocatable)
- Memoria: 6.7 GB (~4.9 GB allocatable)
- Storage: 50 GB SSD
- Red: 250 Mbps garantizado

Capacidad total del cluster:
- CPU Total: 6 vCores (5.52 vCores allocatable)
- Memoria Total: 20.1 GB (14.7 GB allocatable)
```

**Uso actual de recursos:**

| Nodo | CPU Usado | CPU Disponible | RAM Usada | RAM Disponible | Estado |
|------|-----------|----------------|-----------|----------------|--------|
| tractus-x-umbrella-node-257213 | 1039m (56%) | 781m | 2.0 GB (41%) | 2.8 GB | ‚ö†Ô∏è Medio |
| tractus-x-umbrella-node-7a82a3 | 1529m (83%) | 311m | 2.4 GB (48%) | 2.5 GB | üî¥ Alto |
| tractus-x-umbrella-node-fe2278 | 1477m (80%) | 363m | 2.8 GB (57%) | 2.0 GB | üî¥ Alto |

**Pods activos:** 49 pods corriendo correctamente

**Problemas identificados:**
- ‚ö†Ô∏è **CPU casi saturada** en 2 de 3 nodos (80-83% uso)
- ‚ö†Ô∏è L√≠mites de CPU en nodo 3 en **overcommit** (108%)
- ‚ö†Ô∏è Poco margen para nuevos componentes (~300-700m CPU libre por nodo)
- ‚ùå Sin PersistentVolumes disponibles (0 PVs)

### 1.4. Componentes Necesarios para Onboarding

**Estimaci√≥n de recursos adicionales requeridos:**

| Componente | CPU Request | Memory Request | R√©plicas |
|------------|-------------|----------------|----------|
| BPDM Gate | 250m | 512Mi | 1 |
| BPDM Pool | 250m | 512Mi | 1 |
| BPDM Cleaning Service | 100m | 256Mi | 1 |
| BPDM Postgres (adicional) | 250m | 256Mi | 1 |
| SSI Credential Issuer | 500m | 1Gi | 1 |
| Issuer Postgres | 250m | 256Mi | 1 |
| SMTP4Dev | 100m | 128Mi | 1 |
| Identity Trust Bundle | 300m | 512Mi | 1-2 |
| Self Description | 200m | 256Mi | 1 |
| **Total Nuevos Componentes** | **~2.2 vCores** | **~3.7 GB** | |

**Recursos ya desplegados (Portal b√°sico):**
- Portal + Keycloak + Databases ‚âà 3-4 vCores, 6-8 GB RAM

**Total necesario para Onboarding completo:**
- **CPU Total:** ~5.5-6.5 vCores
- **Memory Total:** ~10-12 GB RAM

**Conclusi√≥n:** El cluster actual con 5.52 vCores allocatable est√° al l√≠mite y **NO puede soportar los componentes adicionales**.

---

## 2. Propuesta de Soluci√≥n

### 2.1. Alternativas Evaluadas

#### **Alternativa 1: Aumentar N√∫mero de Nodos (No Viable)**

**Propuesta:** Pasar de 3 a 4-5 nodos con el mismo flavor b2-7

**Pros:**
- F√°cil de implementar
- Sin cambio de flavor

**Contras:**
- ‚ùå Costo lineal (a√±adir 1 nodo = +33% costo)
- ‚ùå No mejora el rendimiento individual de los nodos
- ‚ùå Mayor complejidad de gesti√≥n
- ‚ùå Los nodos seguir√≠an siendo peque√±os (2 vCores cada uno)

**Costo:**
- 4 nodos √ó 0.0681 ‚Ç¨/hora = 0.27 ‚Ç¨/hora (~65‚Ç¨/mes) - **+33%**
- 5 nodos √ó 0.0681 ‚Ç¨/hora = 0.34 ‚Ç¨/hora (~82‚Ç¨/mes) - **+67%**

**Veredicto:** ‚ùå No recomendado - Mejor usar nodos m√°s potentes

---

#### **Alternativa 2: Actualizar a B2-15 (Viable pero No √ìptimo)**

**Propuesta:** Cambiar a flavor b2-15 (doble de recursos que b2-7)

**Especificaciones:**
- CPU: 4 vCores por nodo √ó 3 = **12 vCores total**
- Memoria: 15 GB por nodo √ó 3 = **45 GB RAM total**
- Storage: 100 GB SSD
- Red: 250 Mbps garantizado (igual que b2-7)

**Pros:**
- ‚úÖ Doble de capacidad
- ‚úÖ Suficiente para onboarding completo

**Contras:**
- ‚ö†Ô∏è Misma generaci√≥n (serie B2)
- ‚ö†Ô∏è Misma velocidad de red (250 Mbps)
- ‚ö†Ô∏è Storage SSD (no NVMe)
- ‚ùå Costo elevado

**Costo:**
- 3 nodos √ó 0.129 ‚Ç¨/hora = 0.39 ‚Ç¨/hora (~94‚Ç¨/mes)
- **Incremento:** +92% respecto al actual

**Veredicto:** ‚ö†Ô∏è Viable pero no es la mejor opci√≥n - Hay mejores alternativas

---

#### **Alternativa 3: Actualizar a B2-30 (Sobrecapacidad)**

**Propuesta:** Cambiar a flavor b2-30 (cu√°druple de recursos)

**Especificaciones:**
- CPU: 8 vCores por nodo √ó 3 = **24 vCores total**
- Memoria: 30 GB por nodo √ó 3 = **90 GB RAM total**

**Pros:**
- ‚úÖ Capacidad de sobra
- ‚úÖ Preparado para crecimiento futuro (EDCs, m√°s componentes)

**Contras:**
- ‚ùå Sobrecapacidad innecesaria a corto plazo
- ‚ùå Costo muy elevado
- ‚ö†Ô∏è Misma generaci√≥n B2

**Costo:**
- 3 nodos √ó 0.261 ‚Ç¨/hora = 0.78 ‚Ç¨/hora (~190‚Ç¨/mes)
- **Incremento:** +287% respecto al actual

**Veredicto:** ‚ùå No recomendado - Exceso de capacidad para necesidades actuales

---

#### **Alternativa 4: Actualizar a B3-16 (RECOMENDADA) ‚úÖ**

**Propuesta:** Cambiar a flavor b3-16 de **nueva generaci√≥n**

**Especificaciones:**
- CPU: 4 vCores por nodo √ó 3 = **12 vCores total**
- Memoria: 16 GB por nodo √ó 3 = **48 GB RAM total**
- Storage: 100 GB **NVMe** (m√°s r√°pido que SSD)
- Red: **1 Gbps** (4√ó m√°s r√°pido que b2-7)
- Tecnolog√≠a: **Nueva generaci√≥n B3** (mejor rendimiento)

**Pros:**
- ‚úÖ **Doble de CPU** (12 vs 6 vCores)
- ‚úÖ **Triple de RAM** (48GB vs 21GB)
- ‚úÖ **Storage NVMe** (m√°s r√°pido)
- ‚úÖ **Red 4√ó m√°s r√°pida** (1 Gbps vs 250 Mbps)
- ‚úÖ **Nueva generaci√≥n** (mejor eficiencia)
- ‚úÖ **Precio competitivo** (m√°s barato que b2-15)
- ‚úÖ Capacidad suficiente para onboarding + margen de crecimiento

**Contras:**
- ‚ö†Ô∏è Requiere recrear el nodepool (downtime de ~10 minutos)

**Costo:**
- 3 nodos √ó 0.093 ‚Ç¨/hora = 0.28 ‚Ç¨/hora (~68‚Ç¨/mes)
- **Incremento:** +38% respecto al actual (+19‚Ç¨/mes)

**Capacidad disponible despu√©s del onboarding:**
- CPU libre: ~4-5 vCores (**40-45% disponible**)
- RAM libre: ~30 GB (**70% disponible**)
- **Margen excelente** para crecimiento y picos de carga

**Veredicto:** ‚úÖ **RECOMENDADO** - Mejor relaci√≥n precio/rendimiento/capacidad

---

### 2.2. Comparativa de Alternativas

| Criterio | B2-7 (Actual) | B2-15 | B2-30 | **B3-16** ‚úÖ |
|----------|---------------|-------|-------|-------------|
| **CPU Total** | 6 vCores | 12 vCores | 24 vCores | **12 vCores** |
| **RAM Total** | 21 GB | 45 GB | 90 GB | **48 GB** |
| **Storage** | 50GB SSD | 100GB SSD | 200GB SSD | **100GB NVMe** |
| **Red** | 250 Mbps | 250 Mbps | 500 Mbps | **1 Gbps** |
| **Generaci√≥n** | B2 | B2 | B2 | **B3 (nueva)** |
| **Costo/mes** | 49‚Ç¨ | 94‚Ç¨ | 190‚Ç¨ | **68‚Ç¨** |
| **Incremento** | - | +92% | +287% | **+38%** |
| **Capacidad para Onboarding** | ‚ùå Insuficiente | ‚úÖ Suficiente | ‚úÖ Sobrada | ‚úÖ **√ìptima** |
| **Margen futuro** | ‚ùå 0% | ‚ö†Ô∏è 20-30% | ‚úÖ 60-70% | ‚úÖ **40-50%** |
| **Rendimiento** | B√°sico | B√°sico | Medio | **Alto (nueva gen)** |

### 2.3. Decisi√≥n Final

**Soluci√≥n seleccionada:** **Actualizar a B3-16**

**Justificaci√≥n:**
1. ‚úÖ **Mejor relaci√≥n calidad-precio:** +38% costo por 100% m√°s recursos y mejor tecnolog√≠a
2. ‚úÖ **Capacidad suficiente:** 12 vCores y 48GB RAM cubren onboarding + margen del 40-50%
3. ‚úÖ **Nueva generaci√≥n:** Mayor eficiencia y rendimiento (NVMe, red 1Gbps)
4. ‚úÖ **M√°s barato que B2-15:** A pesar de ser nueva generaci√≥n y tener m√°s RAM
5. ‚úÖ **Escalabilidad:** Preparado para a√±adir EDCs y otros componentes en el futuro
6. ‚úÖ **Simplicidad:** Mantener 3 nodos (misma arquitectura)

---

## 3. Cambios a Implementar

### 3.1. Archivos a Modificar

**Archivo:** `terraform-ovh/main.tf`

**Cambio a realizar:**

```diff
# 4. El Grupo de Nodos: "tractus-x-umbrella"
resource "ovh_cloud_project_kube_nodepool" "node_pool" {
  service_name  = var.ovh_service_name
  kube_id       = ovh_cloud_project_kube.my_kube_cluster.id
  name          = "tractus-x-umbrella"
- flavor_name   = "b2-7"     # Tipo de nodo B2-7 (Prop√≥sito General)
+ flavor_name   = "b3-16"    # Tipo de nodo B3-16 (Nueva Generaci√≥n - Mejor rendimiento)
  desired_nodes = 3
  max_nodes     = 3
  min_nodes     = 3
}
```

### 3.2. Procedimiento de Implementaci√≥n

#### **Paso 1: Backup de Configuraci√≥n (Opcional pero Recomendado)**

```bash
cd /home/xmendialdua/projects/assembly/tractus-x-umbrella

# Backup del kubeconfig
cp kubeconfig.yaml kubeconfig.yaml.backup-$(date +%Y%m%d)

# Backup del archivo Terraform
cp terraform-ovh/main.tf terraform-ovh/main.tf.backup-$(date +%Y%m%d)
```

#### **Paso 2: Modificar Archivo Terraform**

```bash
cd /home/xmendialdua/projects/assembly/tractus-x-umbrella/terraform-ovh

# Editar el archivo main.tf
# Cambiar: flavor_name = "b2-7"
# Por:     flavor_name = "b3-16"
```

**Nota:** Este cambio ya fue realizado el 27/01/2026.

#### **Paso 3: Verificar Cambios con Terraform Plan**

```bash
cd /home/xmendialdua/projects/assembly/tractus-x-umbrella/terraform-ovh

# Ver qu√© cambios se van a realizar
terraform plan
```

**Salida esperada:**
```
Terraform will perform the following actions:

  # ovh_cloud_project_kube_nodepool.node_pool must be replaced
-/+ resource "ovh_cloud_project_kube_nodepool" "node_pool" {
      ~ flavor_name   = "b2-7" -> "b3-16" # forces replacement
      ~ id            = "xxx" -> (known after apply)
        name          = "tractus-x-umbrella"
        desired_nodes = 3
        max_nodes     = 3
        min_nodes     = 3
        # ... (otros atributos sin cambios)
    }

Plan: 1 to add, 0 to change, 1 to destroy.
```

**Interpretaci√≥n:**
- ‚ö†Ô∏è `must be replaced` = Terraform destruir√° el nodepool viejo y crear√° uno nuevo
- ‚ö†Ô∏è Esto causar√° **downtime** de aproximadamente 10-15 minutos
- ‚úÖ Los recursos de Kubernetes (Ingress, LoadBalancer) **NO se ver√°n afectados**
- ‚úÖ La IP p√∫blica (51.68.114.44) **se mantendr√°**

#### **Paso 4: Aplicar Cambios**

```bash
# Aplicar los cambios
terraform apply

# Terraform pedir√° confirmaci√≥n
# Escribir: yes
```

**Proceso que seguir√° Terraform:**
1. Marca el nodepool actual para eliminaci√≥n
2. Crea un nuevo nodepool con flavor b3-16
3. Provisiona 3 nuevos nodos
4. Elimina el nodepool antiguo
5. Los nodos viejos se desconectan del cluster

**Tiempo estimado:** 10-15 minutos

**Durante este tiempo:**
- ‚ö†Ô∏è Todos los pods se detendr√°n
- ‚ö†Ô∏è El portal NO estar√° accesible
- ‚ö†Ô∏è Los servicios estar√°n en downtime
- ‚úÖ NO se perder√°n configuraciones de Kubernetes
- ‚úÖ Los PersistentVolumeClaims se preservar√°n (si los hubiera)

#### **Paso 5: Verificar Nuevos Nodos**

```bash
export KUBECONFIG=/home/xmendialdua/projects/assembly/tractus-x-umbrella/kubeconfig.yaml

# Listar nodos del cluster
kubectl get nodes

# Deber√≠as ver algo como:
# NAME                               STATUS   ROLES    AGE     VERSION
# tractus-x-umbrella-node-xxxxxx     Ready    <none>   5m      v1.34.2
# tractus-x-umbrella-node-yyyyyy     Ready    <none>   5m      v1.34.2
# tractus-x-umbrella-node-zzzzzz     Ready    <none>   5m      v1.34.2
```

**Verificar especificaciones de los nodos:**
```bash
# Ver capacidad de los nuevos nodos
kubectl describe nodes | grep -E "Name:|cpu:|memory:" | head -20

# Salida esperada:
# Name:               tractus-x-umbrella-node-xxxxxx
#   cpu:                4          ‚Üê Antes era 2
#   memory:             16386048Ki  ‚Üê Antes era ~7GB
#   cpu:                3840m       ‚Üê Allocatable
#   memory:             14501888Ki  ‚Üê Allocatable (~14GB)
```

#### **Paso 6: Verificar Recursos Disponibles**

```bash
# Ver recursos asignados vs disponibles
kubectl describe nodes | grep -A 5 "Allocated resources"
```

**Salida esperada (nodos nuevos y vac√≠os):**
```
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                250m (6%)   0 (0%)      ‚Üê Muy bajo, solo sistema
  memory             170Mi (1%)  170Mi (1%)  ‚Üê Muy bajo, solo sistema
```

#### **Paso 7: Verificar que los Pods se Re-despliegan**

```bash
# Ver todos los pods en el namespace portal
kubectl get pods -n portal

# Monitorear en tiempo real
kubectl get pods -n portal -w
```

**Todos los pods deber√≠an pasar a estado `Running` autom√°ticamente** gracias a los Deployments/StatefulSets de Kubernetes.

**Pods esperados en estado Running:**
- portal-administration-service
- portal-assets
- portal-marketplace-app-service
- portal-notification-service
- portal-registration
- portal-registration-service
- portal-services-service
- portal-portal (frontend)
- portal-pgadmin4
- portal-centralidp-0
- portal-centralidp-postgresql-0
- portal-sharedidp-0
- portal-sharedidp-postgresql-0
- portal-portal-backend-postgresql-0
- bpdm-postgres-0
- portal-bpdm-orchestrator
- portal-selfdescription
- portal-ssi-credential-issuer-processesworker

**Si alg√∫n pod no arranca correctamente:**
```bash
# Ver detalles del pod
kubectl describe pod <nombre-pod> -n portal

# Ver logs
kubectl logs <nombre-pod> -n portal
```

#### **Paso 8: Verificar Ingress y LoadBalancer**

```bash
# Verificar que el Ingress mantiene la misma configuraci√≥n
kubectl get ingress -n portal

# Verificar que la IP p√∫blica se mantiene
kubectl get svc -n portal | grep LoadBalancer
```

**IP esperada:** 51.68.114.44 (debe mantenerse igual)

#### **Paso 9: Verificar Acceso al Portal**

```bash
# Probar acceso web
curl -k https://portal.51.68.114.44.nip.io

# Deber√≠a responder con c√≥digo 200 o redirigir
```

**Verificaci√≥n en navegador:**
1. Abrir https://portal.51.68.114.44.nip.io
2. Login con credenciales de administrador
3. Verificar que el portal funciona correctamente

---

## 4. Nueva Soluci√≥n Desplegada

### 4.1. Configuraci√≥n del Cluster Actualizado

**Proveedor:** OVH Public Cloud  
**Regi√≥n:** GRA5 (Gravelines, Francia)  
**Cluster:** dataspace (Kubernetes 1.34)  
**Nodepool:** tractus-x-umbrella  

**Especificaciones del Nodepool:**

| Par√°metro | Valor |
|-----------|-------|
| **Flavor** | b3-16 (Nueva Generaci√≥n) |
| **N√∫mero de Nodos** | 3 |
| **CPU por Nodo** | 4 vCores |
| **Memoria por Nodo** | 16 GB |
| **Storage por Nodo** | 100 GB NVMe |
| **Red Garantizada** | 1 Gbps |
| **Red M√°xima** | 4 Gbps |

**Capacidad Total del Cluster:**

| Recurso | Capacidad Total | Allocatable | Mejora vs Anterior |
|---------|----------------|-------------|-------------------|
| **CPU** | 12 vCores | ~11 vCores | **+100% (6‚Üí12)** |
| **Memoria** | 48 GB | ~42 GB | **+130% (21‚Üí48)** |
| **Storage** | 300 GB NVMe | - | **+100% + NVMe** |
| **Red** | 1 Gbps/nodo | - | **+300% (250Mbps‚Üí1Gbps)** |

**Costo:**
- **Por hora:** 0.28 ‚Ç¨/hora (3 nodos √ó 0.093 ‚Ç¨/hora)
- **Mensual:** ~68 ‚Ç¨/mes
- **Incremento:** +19 ‚Ç¨/mes (+38%)

### 4.2. Comandos de Verificaci√≥n

#### **Verificar Estado General del Cluster**

```bash
export KUBECONFIG=/home/xmendialdua/projects/assembly/tractus-x-umbrella/kubeconfig.yaml

# 1. Verificar que los 3 nodos est√°n Ready
kubectl get nodes

# Salida esperada:
# NAME                               STATUS   ROLES    AGE   VERSION
# tractus-x-umbrella-node-xxxxxx     Ready    <none>   XXm   v1.34.2
# tractus-x-umbrella-node-yyyyyy     Ready    <none>   XXm   v1.34.2
# tractus-x-umbrella-node-zzzzzz     Ready    <none>   XXm   v1.34.2

# 2. Verificar capacidad total
kubectl get nodes -o json | jq '.items[] | {name:.metadata.name, cpu:.status.capacity.cpu, memory:.status.capacity.memory}'

# Salida esperada (por cada nodo):
# {
#   "name": "tractus-x-umbrella-node-xxxxxx",
#   "cpu": "4",           ‚Üê Debe ser 4 (antes era 2)
#   "memory": "16386048Ki" ‚Üê Debe ser ~16GB (antes era ~7GB)
# }
```

#### **Verificar Uso de Recursos**

```bash
# Ver uso actual de CPU y memoria (requiere metrics-server)
kubectl top nodes

# Salida esperada (nodos reci√©n creados):
# NAME                               CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
# tractus-x-umbrella-node-xxxxxx     XXXm         X%     XXXXMi          XX%
# tractus-x-umbrella-node-yyyyyy     XXXm         X%     XXXXMi          XX%
# tractus-x-umbrella-node-zzzzzz     XXXm         X%     XXXXMi          XX%

# Ver recursos detallados asignados
kubectl describe nodes | grep -A 5 "Allocated resources"

# Con los pods del portal b√°sico redesplegados, deber√≠as ver:
# - CPU: ~30-40% de uso (mucho mejor que el 80-83% anterior)
# - Memory: ~20-30% de uso (mucho mejor que el 40-57% anterior)
```

#### **Verificar Estado de Pods**

```bash
# Ver todos los pods en el namespace portal
kubectl get pods -n portal

# Todos deben estar en estado Running (1/1 Ready)
# Contar pods Running
kubectl get pods -n portal | grep Running | wc -l

# Verificar que no hay pods con problemas
kubectl get pods --all-namespaces --field-selector=status.phase!=Running,status.phase!=Succeeded

# Idealmente deber√≠a devolver: "No resources found"
# O solo jobs completados antiguos
```

#### **Verificar Componentes Espec√≠ficos**

```bash
# Verificar Keycloak (Identity Providers)
kubectl get pods -n portal | grep idp

# Salida esperada:
# portal-centralidp-0                      1/1     Running
# portal-centralidp-postgresql-0           1/1     Running
# portal-sharedidp-0                       1/1     Running
# portal-sharedidp-postgresql-0            1/1     Running

# Verificar Backend del Portal
kubectl get pods -n portal | grep -E "portal-(administration|marketplace|notification|registration|services)"

# Verificar Base de Datos Principal
kubectl get pods -n portal | grep postgresql

# Verificar Frontend
kubectl get pods -n portal | grep "portal-portal"
```

#### **Verificar Ingress y Conectividad**

```bash
# Verificar configuraci√≥n de Ingress
kubectl get ingress -n portal

# Verificar que la IP del LoadBalancer no ha cambiado
kubectl get svc -n portal -o wide | grep LoadBalancer

# La EXTERNAL-IP debe seguir siendo: 51.68.114.44
```

#### **Prueba de Conectividad Web**

```bash
# Probar endpoint del Portal
curl -k https://portal.51.68.114.44.nip.io

# Probar Keycloak Central
curl -k https://centralidp.51.68.114.44.nip.io

# Probar Keycloak Shared
curl -k https://sharedidp.51.68.114.44.nip.io

# Todos deben responder con c√≥digo 200 o redirecciones HTML
```

### 4.3. M√©tricas de √âxito

**El despliegue se considera exitoso cuando:**

‚úÖ **Infraestructura:**
- [ ] Los 3 nodos est√°n en estado `Ready`
- [ ] Cada nodo muestra 4 vCores y ~16GB RAM
- [ ] Uso de CPU en los nodos est√° por debajo del 50%
- [ ] Uso de RAM en los nodos est√° por debajo del 40%

‚úÖ **Aplicaciones:**
- [ ] Todos los pods del portal est√°n en estado `Running (1/1)`
- [ ] No hay pods en estado `Pending`, `CrashLoopBackOff` o `Error`
- [ ] Los StatefulSets (Keycloak, PostgreSQL) tienen todas las r√©plicas ready

‚úÖ **Conectividad:**
- [ ] El Ingress responde correctamente
- [ ] La IP del LoadBalancer se mantiene (51.68.114.44)
- [ ] El portal es accesible desde el navegador
- [ ] Login funciona correctamente

‚úÖ **Capacidad para Onboarding:**
- [ ] Hay al menos 4-5 vCores de CPU disponible
- [ ] Hay al menos 30 GB de RAM disponible
- [ ] Se pueden provisionar PersistentVolumes (si es necesario)

### 4.4. Capacidad Disponible para Componentes de Onboarding

**Recursos Totales Allocatable:**
- CPU: ~11 vCores
- RAM: ~42 GB

**Recursos Usados (Portal B√°sico):**
- CPU: ~3-4 vCores
- RAM: ~6-8 GB

**Recursos Disponibles para Onboarding:**
- CPU libre: **~6-7 vCores** (suficiente para los 2.2 vCores requeridos)
- RAM libre: **~34-36 GB** (suficiente para los 3.7 GB requeridos)

**Margen de seguridad:**
- CPU: 300-400% de margen sobre lo requerido
- RAM: 900-1000% de margen sobre lo requerido

‚úÖ **Conclusi√≥n:** El cluster tiene capacidad **m√°s que suficiente** para desplegar todos los componentes de onboarding con un margen de seguridad muy amplio.

---

## 5. Pr√≥ximos Pasos: Despliegue de Componentes de Onboarding

Con el cluster actualizado, se puede proceder al despliegue gradual de los componentes de onboarding siguiendo la estrategia por fases documentada en [2026.01.26 - Despliegue Componentes Onboarding - Estado y Proximos Pasos.md](./2026.01.26%20-%20Despliegue%20Componentes%20Onboarding%20-%20Estado%20y%20Proximos%20Pasos.md)

### 5.1. Estrategia de Despliegue por Fases

**Fase 1: BPDM (Business Partner Data Management)**
- Habilitar: `bpdm.enabled: true`
- Componentes: Gate, Pool, Cleaning Service, Orchestrator
- Tiempo estimado: 10-15 minutos
- Recursos: ~1 vCore, 1.5 GB RAM

**Fase 2: SMTP4Dev**
- Habilitar: `smtp4dev.enabled: true`
- Beneficio: Visualizar emails de invitaci√≥n
- Recursos: ~100m CPU, 128 MB RAM

**Fase 3: SSI Credential Issuer**
- Habilitar: `ssi-credential-issuer.enabled: true`
- Componentes: Issuer, Postgres, ProcessesWorker
- Recursos: ~1 vCore, 1.5 GB RAM

**Fase 4: Identity Trust Bundle + Self Description**
- Habilitar: `identity-and-trust-bundle.enabled: true`
- Habilitar: `selfdescription.enabled: true`
- Recursos: ~500m CPU, 768 MB RAM

### 5.2. Comandos para Despliegue Gradual

```bash
# Fase 1: Habilitar solo BPDM
cd ~/projects/assembly/tractus-x-umbrella/charts/umbrella

# Editar values-adopter-portal-for-onboarding.yaml
# Asegurarse que solo bpdm.enabled: true

helm upgrade portal . \
  -f values-adopter-portal-for-onboarding.yaml \
  -f values-ovh-hosts-portal.yaml \
  -n portal

# Monitorear despliegue
kubectl get pods -n portal -w

# Verificar BPDM espec√≠ficamente
kubectl get pods -n portal | grep bpdm

# Resultado esperado:
# bpdm-postgres-0                      1/1     Running
# portal-bpdm-gate-xxx                 1/1     Running  ‚Üê NUEVO
# portal-bpdm-pool-xxx                 1/1     Running  ‚Üê NUEVO
# portal-bpdm-orchestrator-xxx         1/1     Running
# portal-bpdm-cleaning-service-xxx     1/1     Running  ‚Üê NUEVO
```

**Repetir el proceso para cada fase**, habilitando componentes adicionales progresivamente.

---

## 6. Rollback Plan (Plan de Contingencia)

En caso de que el nuevo cluster presente problemas, se puede volver al flavor anterior:

### 6.1. Pasos para Rollback

```bash
cd /home/xmendialdua/projects/assembly/tractus-x-umbrella/terraform-ovh

# 1. Restaurar backup del archivo main.tf
cp main.tf.backup-YYYYMMDD main.tf

# O editar manualmente:
# flavor_name = "b3-16" ‚Üí "b2-7"

# 2. Aplicar cambios
terraform plan
terraform apply

# 3. Esperar ~10 minutos

# 4. Verificar
kubectl get nodes
```

**Nota:** Al hacer rollback se perder√° nuevamente la capacidad para desplegar componentes de onboarding.

### 6.2. Alternativas al Rollback

Si hay problemas con B3-16, considerar:
1. Probar con B3-8 (m√°s econ√≥mico, menos potencia)
2. Probar con B2-15 (generaci√≥n anterior, similar capacidad)
3. Aumentar a 4 nodos con B2-7
4. Escalar a B3-32 (m√°s capacidad)

---

## 7. Monitorizaci√≥n Continua

### 7.1. Comandos de Monitorizaci√≥n Recomendados

**Monitorizaci√≥n diaria:**
```bash
export KUBECONFIG=/home/xmendialdua/projects/assembly/tractus-x-umbrella/kubeconfig.yaml

# Estado general
kubectl get nodes
kubectl top nodes

# Estado de pods
kubectl get pods -n portal | grep -v Running

# Recursos por nodo
kubectl describe nodes | grep -A 5 "Allocated resources"
```

**Configurar alias √∫tiles:**
```bash
# A√±adir al ~/.bashrc
alias k='kubectl'
alias kgn='kubectl get nodes'
alias kgp='kubectl get pods -n portal'
alias ktn='kubectl top nodes'
alias ktp='kubectl top pods -n portal'

# Recargar
source ~/.bashrc
```

### 7.2. Umbrales de Alerta

**CPU:**
- ‚ö†Ô∏è Advertencia: Uso > 60% en 2+ nodos
- üî¥ Cr√≠tico: Uso > 80% en 2+ nodos
- ‚úÖ Normal: Uso < 60%

**Memoria:**
- ‚ö†Ô∏è Advertencia: Uso > 65% en 2+ nodos
- üî¥ Cr√≠tico: Uso > 85% en 2+ nodos
- ‚úÖ Normal: Uso < 65%

**Pods:**
- ‚ö†Ô∏è Cualquier pod en Pending > 5 minutos
- üî¥ Cualquier pod en CrashLoopBackOff
- ‚úÖ Todos los pods en Running

---

## 8. Referencias

**Documentaci√≥n OVH:**
- [Precios Public Cloud OVH](https://www.ovhcloud.com/es-es/public-cloud/prices/)
- [OVH Managed Kubernetes](https://www.ovhcloud.com/es-es/public-cloud/kubernetes/)

**Documentaci√≥n Catena-X:**
- [Tractus-X Umbrella Chart](https://github.com/eclipse-tractusx/tractus-x-umbrella)
- [Portal Documentation](https://github.com/eclipse-tractusx/portal)

**Documentos relacionados:**
- [2026.01.26 - Despliegue Componentes Onboarding - Estado y Proximos Pasos.md](./2026.01.26%20-%20Despliegue%20Componentes%20Onboarding%20-%20Estado%20y%20Proximos%20Pasos.md)
- [historial_despliegue_ovh.md](./historial_despliegue_ovh.md)

---

## 9. Registro de Cambios

| Fecha | Acci√≥n | Responsable | Estado |
|-------|--------|-------------|--------|
| 26/01/2026 | Identificaci√≥n del problema de recursos | - | ‚úÖ Completado |
| 27/01/2026 | An√°lisis de alternativas | - | ‚úÖ Completado |
| 27/01/2026 | Decisi√≥n: Actualizar a B3-16 | - | ‚úÖ Completado |
| 27/01/2026 | Modificaci√≥n de main.tf | - | ‚úÖ Completado |
| 27/01/2026 | Aplicaci√≥n de cambios Terraform | - | ‚è≥ Pendiente |
| 27/01/2026 | Verificaci√≥n del cluster actualizado | - | ‚è≥ Pendiente |
| 27/01/2026+ | Despliegue componentes onboarding (Fase 1-4) | - | ‚è≥ Pendiente |

---

**Documento creado:** 27 de Enero de 2026  
**√öltima actualizaci√≥n:** 27 de Enero de 2026  
**Estado:** En progreso - Cambios en Terraform aplicados, pendiente de ejecuci√≥n
